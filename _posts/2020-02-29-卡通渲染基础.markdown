---
layout:     post
title:      "unity卡通渲染基础实现"
subtitle:   ""
date:       2020-02-09
author:     "CodeSuperHero"
header-img: "img/toonshading/111.png"
tags:
    - Unity
    - shader
    - toon
---

# shader

### shader 是什么

shader(着色器)是一种用于图像处理的计算机程序。和lua一样，shader也是嵌入到渲染管线中的解释执行的脚本语言，渲染管线通过调用固定的函数来执行我们编写的shader程序。

- GLSL, opengl 平台支持的shader语法
- HLSL, DirectX 平台支持的shader语法
- CG, Nvidia 推出的跨平台shader语法
- 本文以 CG 语法，Unity引擎作为基础进行讲解

### 渲染管线
理解shader前，我们需要先理解调用shader代码的框架：渲染管线(Render Pipline)

<center><img src="img/toonshading//renderpipline.jpg" width = "556" height = "81" align=center alt="rp"/></center>
<center>Real-time Rendering 4th</center>
- 应用阶段：CPU 阶段，处理各种渲染资源，调用GPU绘制接口，传递渲染数据。 drawcall数代表cpu调用GPU的次数，单纯的drawcall指令已经不是性能瓶颈，我们更应该关注 setpasscall 和 uploadtexture 的性能
- 几何阶段：GPU 接收应用阶段数据，执行模型顶点变换，输出顶点变换后的数据。对应shader代码的 vertex 函数。这个阶段是GPU执行效率最高的阶段，多数Shader优化都是将后续的处理移动到几何阶段来完成
- 光栅化阶段：接收插值后的几何阶段数据，计算每个输入数据的颜色，并输出到
- 像素阶段：接收光栅化阶段输出的颜色，并绘制到frambuffer，等待buffer渲染到屏幕

渲染管线其实是非常复杂的，但我们不需要理解其中的细节，只需要在大脑中构建出基本的流程，并清除每个阶段处理的事情即可。
渲染管线为shader编写基础，但是一些纯算法shader是不太需要理解渲染管线的，例如：后处理，compute shader等。

- 现代渲染管线是不区分2d游戏还是3d游戏的。 2d渲染是通过自动生成的网格信息，通过3d渲染管线完成。

### unity shader 基础结构
我们先来看一段简单的Unity shader代码，这段shader代码是让Unity绘制指定的一张图片

```
Shader "Unlit/NewUnlitShader"                   //shader名字，动态加载需要以shader名字作为参数
{
    Properties                                  //属性块，在Unity界面填写的属性都必须在这里声明
    {
        _MainTex ("Texture", 2D) = "white" {}   //声明一个贴图类型的变量，在unity界面需要给这个贴图赋值
    }

    SubShader                                   //子shader, 一个shader可以有多个子shader,但一次渲染只会选择一个subshader执行。
    {
        Tags { "RenderType"="Opaque" }          //unity的tag语法，具体请查阅unity手册
        LOD 100                                 //lod级别，通过lod级别控制是否执行这段shader

        Pass                                    //通道，一个子shader可以有多个pass,从上到下依次执行
        {
            CGPROGRAM                           //指定shader语法为CG，unity还支持 HLSLPROGRAM
            #pragma vertex vert                 //指定 vert 函数替换渲染管线中的 vertex 函数
            #pragma fragment frag               //指定 frag 函数替换渲染管线中的 fragment 函数

            #include "UnityCG.cginc"            //引入Unity提供的cg库函数

            struct appdata                      //获取渲染管线中存储的应用层数据
            {
                float4 vertex : POSITION;       //模型顶点坐标，位于模型坐标系
                float2 uv : TEXCOORD0;          //模型顶点UV，与顶点是1对1的关系
            };

            struct v2f                          //自定义结构，用于在几何阶段和光栅化阶段传递数据，shader表现
            {                                   //为顶点函数返回，片段函数接收
                float2 uv : TEXCOORD0;          //处理后的uv值
                float4 vertex : SV_POSITION;    //处理后的模型顶点坐标，位于裁减空间。SV_POSITION 是GPU上的专用寄存器，shader代码必须填充这个寄存器，渲染管线会直接读取寄存器上面的值作为顶点坐标。SV ： System Value。
            };

            sampler2D _MainTex;                 //uniform变量，是属性块里面声明的变量的一个引用
            float4 _MainTex_ST;                 //XX_ST，贴图缩放和偏移变量，存储编辑器里面的 Tiling 和 Offset变量

            v2f vert (appdata v)                //几何阶段，渲染管线填充appdata数据结构，并调用vert方法处理顶点
            {
                v2f o;                          //声明返回对象
                o.vertex = UnityObjectToClipPos(v.vertex);  //Unity内置函数，将模型空间坐标转换到裁减空间
                o.uv = TRANSFORM_TEX(v.uv, _MainTex);       //通过 _MainTex_ST 变量处理模型uv
                return o;                       //返回处理完成的数据
            }
            

            fixed4 frag (v2f i) : SV_Target     //光栅化阶段，接收几何阶段的顶点函数数据，返回颜色值，存储在SV_Target 寄存器上，供渲染管线读取
            {
                fixed4 col = tex2D(_MainTex, i.uv);         //采样贴图颜色
                return col;                                 //返回得到贴图颜色值
            }
            ENDCG
        }
    }
}
```

这段shader代码在几何阶段的 vert 函数做了基础的顶点和uv变换，在光栅化阶段的 frag 函数做了基础的颜色采样，最终在屏幕上的输出就是 _MainTex 图片。通过这段代码，我们可以学习到unity shader的基础结构

```
Shader
{
    Properties {}
    SubShader {
        ...
        Pass {
            ...
            vertex () { }
            fragment () { }
        }
        Pass { }
    }
    SubShader {
        ...
    }
}
```

- 注意每多一个pass，则会多一个drawcall和setpasscall
- 写shader其实就是按照这套框架填充Unity 和 CG提供的接口

### shader 的种类

shader没有严格分类，对于平时开发大致可以分为 Unlit Shader, Compute Shader, LightingShader

- Unlit Shader不处理光照信息，只做顶点/片段计算。通常用于 UI 界面、后处理、以及一些图形算法。
- Compute Shader有严格的平台和shader model版本限制，可以用于在CPU端处理密集并行计算，最近大热的 Forward+ 渲染管线在unity上就需要通过 compute shader 实现
- Lighting Shader就是一般3D渲染的shader， 它与Unlit Shader的不同之处在于需要处理光照信息。Surface Shader也是属于这类

接下来将用卡渲的作为例子重点讲解下 LightingShader 的编写

### 卡通渲染

卡通渲染，又称非真实感绘制(NPR,Non-photorealistic rendering)，在画面上有多种表现形式，目前普遍指代动画感渲染，其中又通常指日式卡通渲染。如《崩坏3》《塞尔达传说 旷野之息》

<center><img src="img/toonshading/benghuai3.jpg" width = "366" height = "366" align=center alt="rp"/><img src="img/toonshading/saierda.jpg" width = "366" height = "366" align=center alt="rp"/></center>
#### 光照

开始光照前，我们可以简单了解下Unity中可编程渲染管线的分类

- Forward 前向渲染，逐光源逐Object渲染，渲染复杂度是O(m*n) (m = 光源数，n = 对象数)
- Deferred 延迟渲染，延迟渲染是先把物体渲染到一张 G-Buffer 贴图上，然后逐像素计算光照颜色，渲染复杂度O(m * r) （r = 屏幕分辨率）
本文的shader代码都基于 forward 前向渲染为基础讲解
- Legacy Vertex Lit 顶点光照，前向渲染管线，但是光照计算全部发生在顶点中
- Light Pre-Pass 预计算光照渲染，先逐物体将较少信息存储到G-Buffer, 然后再利用G-Buffer逐光照计算一张 LightBuffer，然后把所有物体送入 Forward管线输出颜色，渲染复杂度O(m+n)
- TBDR (Tile-Base Deferred Rendering) 移动平台的渲染架构，硬件层面支持，这里不做解释
- Forward+ (Foward + Light Culling)，一种改良的 Forward 管线，用于优化渲染复杂度 O(m+n)，是目前移动平台处理多光源需求的最佳解决方案，在Unity可以通过Compute Shader预计算光源分簇来实现

从这两张图片我们可以看到引擎的光照效果，所以我们首先得往上面的shade框架填充一个光照模型。关于光照模型大家可以参考这个[链接](https://www.jordanstevenstechart.com/lighting-models)。我们这里选择应用广泛的lambert光照

```
Tags { "LightMode"="ForwardBase" }

#pragma multi_compile_fwdbase
#include "Lighting.cginc"
#include "AutoLight.cginc"

struct appdata
{
    float4 vertex : POSITION;
    float2 uv : TEXCOORD0;
    half3 normal : NORMAL;
};

struct v2f
{
    float4 pos : SV_POSITION;
    half2 uv : TEXCOORD0;
    half3 wLightDir : TEXCOORD1;
    half3 wNormal : TEXCOORD2;
};

v2f vert(appdata i)
{
    v2f o;
    o.vertex = UnityObjectToClipPos(v.vertex);
    o.uv = TRANSFORM_TEX(v.uv, _MainTex);
    o.wNormal = UnityObjectToWorldNormal(v.normal);
    o.wLightDir = _WorldSpaceLightPos0.xyz;
    return o;
}

fixed3 LambertLight(fixed3 col, half3 wNormal, half3 wLightDir)
{
    half3 normal = normalize(wNormal);
    half3 lightDir = normalize(wLightDir);
    half NdotL = max(0.0, dot(normal, lightDir));
    half3 lambertDiffuse = col * NdotL;
    return lambertDiffuse * _LightColor0.rgb;
}

fixed4 frag (v2f i) : SV_Target
{
    fixed4 col = tex2D(_MainTex, i.uv);
    return fixed4(LambertLight(col, i.wNormal,i.wLightDir), 1.0);
}

```

<center><img src="img/toonshading/lambert.jpg" width = "409" height = "328" align=center alt="rp"/></center>
lambert光照公式截断了背光的颜色，所以背光面会看起来很黑，valve 公司在半条命提出了half lambert
```
half NdotL = dot(normal, lightDir) * 0.5 + 0.5;
```
这个公式虽然提高了整体亮度，但是也损失了颜色区域
<center><img src="img/toonshading/halflambert.jpg" width = "409" height = "328" align=center alt="rp"/></center>
所以后续有改良版本的lambert,叫 diffuse wrap

```
half NdotL = max(0.0, dot(normal, lightDir));// * 0.5 + 0.5;
NdotL = pow(NdotL * 0.5 + 0.5, 2);
```
<center><img src="img/toonshading/diffusewrap.jpg" width = "409" height = "328" align=center alt="rp"/></center>
既完整保留了过度区域，又增加了暗处的颜色，这里展开讲解了 Diffuse shader的几种光照处理，只是想说明在NPR渲染中，没有正确的公式，只要看起来像就是正确的，所以在NPR渲染中大量公式都被修改，比如后面要讲的边缘光处理就是纯靠视觉调整公式。

#### 法线处理

```
o.wNormal = UnityObjectToWorldNormal(v.normal); //顶点法线从模型坐标系转换到世界坐标系

inline float3 UnityObjectToWorldNormal( in float3 norm ) 
{
    #ifdef UNITY_ASSUME_UNIFORM_SCALING         //如果是(x,y,z)统一缩放，则法线正常转换就可以
        return UnityObjectToWorldDir(norm);
    #else                                       //非统一缩放下，需要法线左乘逆转职矩阵
        return normalize(mul(norm, (float3x3)unity_WorldToObject));
    #endif
}
```

vert 函数的输入数据是模型原始数据，位于模型的本地坐标系下，通常需要转换到其它坐标系下面进行计算。
法线的计算分为使用顶点法线或者使用法线贴图，法线贴图通常需要转换到切线空间进行计算，上述例子是顶点法线，转换到世界坐标系进行光照的计算。
法线在模型非统一缩放下，需要法线左乘 unity_ObjectToWorld 的逆转职矩阵。 unity_ObjectToWorld的逆矩阵是 unity_WorldToObject。因为法线只有方向没有坐标，所以取Matrix4x4矩阵的左上角3x3的矩阵，然后用法线右乘，就达到了效果左乘转置矩阵的效果。节省一步转置的过程

```
00 01 02 03     |   RS RS RS T
10 11 12 13     |   RS RS RS T
20 21 22 23     |   RS RS RS T
30 31 32 33     |   0  0  0  1
```
r = rotation. s = scale. t = position

#### 漫反射卡通

前面讲解了 Diffuse 的光照，我们需要对其进行卡通化处理

```
half NdotL = dot(normal, lightDir));
half intensity = step(0, NdotL);
half3 lambertDiffuse = col * intensity * _LightColor0.rgb;
```

<center><img src="img/toonshading/step.jpg" width = "409" height = "328" align=center alt="rp"/></center>
- 分层的地方太过于生硬
- 暗部太黑，丢失了色彩
- 只有两层颜色

```
half NdotL = dot(normal, lightDir);
if(NdotL < -0.33)
{
    intensity = -1;//smoothstep(-1, -0.99, NdotL);
}
else if(NdotL < 0.33)
{
    intensity = smoothstep(0.31, 0.34, NdotL);
}
else
{
    intensity = 1;
}
half3 lambertDiffuse = (intensity * _LightColor0.rgb + UNITY_LIGHTMODEL_AMBIENT) * col;
```
<center><img src="img/toonshading/smoothstep.png" width = "409" height = "328" align=center alt="rp"/></center>
添加了 smoothstep 平滑了过度
添加了 UNITY_LIGHTMODEL_AMBIENT 环境光颜色增加暗部的亮度。
用 if 添加了分层，但是推荐用美术出图来进行分层，还可以起到更好的平滑作用

<center><img src="img/toonshading/ramp.jpg" width = "333" height = "52" align=center alt="rp"/></center>
#### 卡通高光

- 前面提到了 Diffuse + Ambient 光照处理，一个标准的经验模型是 Diffuse + Specular + Ambient。而传统经验模型通常采用 Blinn-Phong 高光模型，我们先看一下经验模型下的颜色是什么样子的。

```
_SpecularGloss ("Specular Gloss", float) = 6
_SpecularPower ("Specular Power", float) = 6
_SpecularColor ("Specular Color", Color) = (1,1,1,1)

struct v2f
{
    ...
    half3 wViewDir : TEXCOORD3;
};

v2f vert (appdata v)
{
    ...
    o.wViewDir = WorldSpaceViewDir(v.vertex);
}

fixed4 frag (v2f i) : SV_Target
{
    fixed4 col = tex2D(_MainTex, i.uv);
    half3 normal = normalize(i.wNormal);
    half3 lightDir = normalize(i.wLightDir);
    half NdotL = max(0, dot(normal, lightDir));

    half3 halfViewDir = normalize(i.wViewDir + i.wLightDir);
    half NdotV = max(0.0, dot(normal, halfViewDir));
    half3 specular = pow(NdotV, _SpecularGloss) * _SpecularPower * _SpecularColor.rgb;

    half3 diffuse = _LightColor0.rgb * NdotL + UNITY_LIGHTMODEL_AMBIENT + specular;
    half3 c = diffuse * col.rgb;
    return fixed4(c, 1);
}
```

<center><img src="img/toonshading/lighting.jpg" width = "409" height = "339" align=center alt="rp"/></center>
一些游戏浓浓的塑料感就是来自于这套光照模型，这里不做更深入的讨论，继续卡通化

```
half3 halfViewDir = normalize(i.wViewDir + lightDir);
half NdotH = dot(normal, halfViewDir);
float specularIntensity = pow(NdotH * intensity, _SpecularGloss);
float specularIntensitySmooth = smoothstep(0.005, 0.01, specularIntensity);
float3 specular = specularIntensitySmooth * _SpecularColor.rgb;
```

<center><img src="img/toonshading/toonspecular.jpg" width = "409" height = "328" align=center alt="rp"/></center>
通过对高光强度值进行二值化从而达到卡通高光的效果

#### 卡通边缘高光

```
float rimValue = 1 - max(0, dot(normal, viewDir));
half3 rimColor = _RimColor.rgb * pow(rimValue, _RimIntensity);
```
<center><img src="img/toonshading/rim.jpg" width = "409" height = "328" align=center alt="rp"/></center>
经验模型的边缘高光就是取法线和视线的点积角度，接近0的地方也就是边缘处，但是这种计算公式出来的边缘高光效果并不好，而且不够卡通。

```
float rimValue = 1 - dot(normal, viewDir);
float rimIntensity = smoothstep(_RimRange - 0.01, _RimRange + 0.01, rimValue);
float3 rimColor = rimIntensity * _RimColor;
```
<center><img src="img/toonshading/toonrim.jpg" width = "409" height = "328" align=center alt="rp"/></center>
瞎改一下公式，看起来好看就够了。这个公式网上找的，没什么道理。
卡通的光照部分大致处理完了。但是大家看到模型的效果并不好，因为卡通渲染还需要大量的静态贴图来辅助，AO贴图，高光MASK贴图，边缘高光的暗部处理，明暗颜色都由贴图来完成等等。这里就体现TA的作用了。

#### 外描边处理

模型外轮廓描边处理通常有三种做法
- 边缘高光实现
- 通过顶点外扩的方式实现
- 通过后处理做边缘检测来实现

上文已经实现了边缘高光，现在大部分游戏的边缘轮廓都是用边缘高光处理，但某些游戏还是依然会有轮廓线，也就是第二种实现方式
1. 所有顶点沿自身法线外扩一定距离
2. 裁减掉面向摄像机的顶点
3. 用描边颜色填充即可
这里要用到之前说的双pass，在绘制模型的pass之前，我们添加一个pass

```
Pass
{
    Cull Front
    CGPROGRAM
    #pragma vertex vert
    #pragma fragment frag
    #include "UnityCG.cginc"
    struct appdata
    {
        float4 vertex : POSITION;
        float3 normal : NORMAL;
        float2 uv : TEXCOORD0;
    };
    struct v2f
    {
        float4 vertex : SV_POSITION;
        float2 uv : TEXCOORD0;
    };
    fixed4 _OutlineColor;
    float _OutlineRange;
    v2f vert (appdata v)
    {
        float4 vertex = float4(v.normal * _OutlineRange + v.vertex.xyz, 1.0);
        v2f o;
        o.vertex = UnityObjectToClipPos(vertex);
        return o;
    }
    fixed4 frag (v2f i) : SV_Target
    {
        return _OutlineColor;
    }
    ENDCG
}
```

<center><img src="img/toonshading/outline.jpg" width = "409" height = "328" align=center alt="rp"/></center>
#### 阴影

如果游戏允许开实时阴影，则调用unity的API。使用Unity的实时阴影。这里介绍一种简易的阴影实现方式。

```
Pass
{
    Tags {"LightMode"="Forwardbase"}
    Stencil
    {
        Ref 0
        Comp Equal
        Pass incrWrap
        Fail keep
        ZFail keep
    }
    Blend SrcAlpha OneMinusSrcAlpha
    ZWrite Off
    Offset -1, -1
    CGPROGRAM
    #pragma target 3.0
    #pragma vertex vert
    #pragma fragment frag
    #pragma multi_compile_fwdbase
    #include "Lighting.cginc"
    struct appdata
    {
        float4 vertex : POSITION;
    };
    struct v2f
    {
        float4 vertex : SV_POSITION;
        float4 uv1 : TEXCOORD0;
    };
    fixed4 _ShadowColor;
    half _ShadowHeight;
    v2f VertShadow (half4 vertex, half3 lightDir, half shadowHeight, fixed4 shadowColor)
    {
        v2f o;
        half3 wPos = mul(unity_ObjectToWorld, vertex).xyz;
        half3 shadowPos;
        shadowPos.y = min(wPos.y, shadowHeight);
        shadowPos.xz =  wPos.xz - lightDir.xz * max(0, wPos.y - shadowHeight) / lightDir.y;
        o.vertex = UnityWorldToClipPos(shadowPos);
        o.uv1 = shadowColor;
        return o;
    }
    v2f vert (appdata v)
    {
        fixed3 lightDir = normalize(_WorldSpaceLightPos0.xyz);
        v2f o = VertShadow(v.vertex, lightDir, _ShadowHeight, _ShadowColor);
        return o;
    }
    fixed4 frag (v2f i) : SV_TARGET
    {
        return i.uv1;
    }
    ENDCG
}

```

通过相似三角形把模型的顶点坐标转换到 "y = shadowHeight" 平面，从而得到相对真实的阴影，但是无法适应不平的地面。
这里出现了三个需要关注的知识点

<center><img src="img/toonshading/shadow.jpg" width = "409" height = "328" align=center alt="rp"/></center>

```
Stencil             // 模板测试，写入模板缓冲
{
    Ref 0           // 写入模板值
    Comp Equal      // 比较方法是 恒等
    Pass incrWrap   // 模板测试通过，循环自增。
    Fail keep       // 模板测试失败，保持当前模板值
    ZFail keep      // 深度测试失败，保持当前模板值
}

ZWrite Off          //关闭 z 值写入

Blend SrcAlpha OneMinusSrcAlpha //颜色混合，当前混合公式 ShaderColor * ShaderAlpha + BufferColor * (1 - ShaderAlpha)
```

第一个是蒙版测试，第二个是颜色混合，第三个是关闭深入写入。这三个操作都集中在渲染管线的光栅化阶段
<center><img src="img/toonshading/guangshanhua.jpg" width = "764" height = "406" align=center alt="rp"/></center>
#### 烘焙处理

如果场景也使用自定义shader，那么我们还需要额外处理烘焙，Unity 的 Enlighten 烘焙系统，需要shader 提供烘焙数据，不然是无法参与烘焙的

```
Pass
{  
    Name "Meta"
    Tags {"LightMode" = "Meta"}
    Cull Off
    CGPROGRAM
    #pragma vertex vert_meta
    #pragma fragment frag_meta
    #include "UnityMetaPass.cginc"
    v2fT4M vert_meta(appdata v)
    {
        v2fT4M o;
        o.pos = UnityMetaVertexPosition(v.vertex, v.uv2, v.uv3.xy, unity_LightmapST, unity_DynamicLightmapST);
        #ifdef EDITOR_VISUALIZATION
            o.vizUV = 0;
            o.lightCoord = 0;
            if (unity_VisualizationMode == EDITORVIZ_TEXTURE)
                o.vizUV = UnityMetaVizUV(unity_EditorViz_UVIndex, v.uv1.xy, v.uv2.xy, v.uv3, unity_EditorViz_Texture_ST);
            else if (unity_VisualizationMode == EDITORVIZ_SHOWLIGHTMASK)
            {
                o.vizUV = v.uv2.xy * unity_LightmapST.xy + unity_LightmapST.zw;
                o.lightCoord = mul(unity_EditorViz_WorldToLight, mul(unity_ObjectToWorld, float4(v.vertex.xyz, 1)));
            }
        #endif
        o.wPos = mul(unity_ObjectToWorld, v.vertex);
        o.wNormal = UnityObjectToWorldNormal(v.normal);
        FOGCOORDS(o.uv.z, o.wPos)
        return o;
}
    fixed4 frag_meta(v2fT4M i):SV_Target
    {
        fixed4 col = tex2D (_MainTex, i.uv.xy).rgba;
        UnityMetaInput metaIN;
        UNITY_INITIALIZE_OUTPUT(UnityMetaInput,metaIN);
        metaIN.Albedo = col;
        metaIN.Emission = 0;
        metaIN.SpecularColor = 0;
        #ifdef EDITOR_VISUALIZATION
            metaIN.VizUV = i.vizUV;
            metaIN.LightCoord = i.lightCoord;
        #endif
        return UnityMetaFragment(metaIN);
    }
    ENDCG
        }
    }
```

这里就是套Unity提供的模板，相关知识请翻阅unity资料

---
这里已经不太想写了...

### FAQ

- 实时光照是不是很消耗？
- grabpass 的消耗
- 类似 metapass 资料很少的知识点，怎么去学习实现
...
